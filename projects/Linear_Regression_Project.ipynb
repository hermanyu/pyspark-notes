{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f213cd7-ba71-43ea-a445-a0231b2bfb6c",
   "metadata": {},
   "source": [
    "# Linear Regression Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda2d2f-1860-4f83-bdf5-87e9289a52b1",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1771a-5688-4a3e-86be-1e4f0d950fa0",
   "metadata": {},
   "source": [
    "This project requires us to build a linear model that predicts the number of crew members needed to man a cruise liner, based on specific features of the cruise ship. The objective the model is predictive accuracy, so the model will primarily be evaluated on it's ability to predict accurately for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f17316-e0c4-4d46-b211-3e250d05fee8",
   "metadata": {},
   "source": [
    "The data set provided contains the following variables:\n",
    "\n",
    "* Ship Name\n",
    "* Cruise Line\n",
    "* Age (as of 2013)\n",
    "* Tonnage (in the 1000s)\n",
    "* Passenger limit (in the 100s)\n",
    "* Length (in the 100s of ft)\n",
    "* Cabins (in the 100s)\n",
    "* Passenger Density\n",
    "* Crew (in the 100s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149efdf-2b6b-49e6-aa1b-e1a6c6da317a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d127d6b-3c33-41df-b1c0-3968f03aa08a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346b853-81ba-4ae8-8811-4c6b5b42cf75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Correlation\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "SEED = 42\n",
    "DATA_PATH = \"../course_materials/Spark_for_Machine_Learning/Linear_Regression/cruise_ship_info.csv\"\n",
    "\n",
    "# initialize spark session\n",
    "spark = SparkSession.builder.appName(\"Linear Regression Project\").getOrCreate()\n",
    "\n",
    "# load data\n",
    "df = spark.read.csv(DATA_PATH, inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619dc75a-7024-45d4-b194-653dd61faf29",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22bbb7-f44e-4efd-98f2-7282082c05aa",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3247a-eff6-42e2-be8c-b7c4dae6c489",
   "metadata": {},
   "source": [
    "### Ship Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0020d45-1845-4a57-8d37-a4f01668b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Rows: \" + str(df.count()))\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac0b29-6194-4b3a-b411-237c345ee5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select( F.countDistinct(df[\"Ship_name\"]).alias(\"Distinct Ship Names\") ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382a173-97fc-486b-82e9-d53146a286f5",
   "metadata": {},
   "source": [
    "There are only 138 distinct ship names despite having 158 rows; this implies that some ship names are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03128aa2-4a95-44d6-b657-58fcd1cd09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Ship_name\").agg(F.count(\"Ship_name\").alias(\"count\")).filter( \"count > 1\" ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51b1a4-cf21-4e3b-bf78-f0a7e412557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter( \"Ship_name = 'Spirit'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82658c16-7759-4935-bc17-06a74fb78fd3",
   "metadata": {},
   "source": [
    "The name \"Spirit\" occurs 4 times, each operated by a different cruise line. It's likely that the `Ship_name` and `Cruise_line` combine to uniquely identify each row in the data set. We can check this with a group by + count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e2394-fea1-400c-99ca-7939d6cb6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy([\"Ship_name\", \"Cruise_line\"]).agg(F.count(\"Ship_name\").alias(\"count\")).filter( \"count > 1\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab168665-939a-45dc-90c1-a9baef2f83d0",
   "metadata": {},
   "source": [
    "We see that no combination of `Ship_name` x `Cruise_line` occurs more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50734b-df96-4c76-ad3b-cea4aaaa8577",
   "metadata": {},
   "source": [
    "## Cruise Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a4636-1bf1-461a-9558-fba373d3d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Cruise_line\").agg(\n",
    "    F.count(\"Ship_name\").alias(\"ships\"), \n",
    "    F.mean(\"age\").alias(\"mean_age\"),\n",
    "    F.mean(\"tonnage\").alias(\"mean_tonnage\"),\n",
    "    F.mean(\"passengers\").alias(\"mean_passengers\"),\n",
    "    F.mean(\"length\").alias(\"mean_length\"),\n",
    "    F.mean(\"cabins\").alias(\"mean_cabins\"),\n",
    "    F.mean(\"passenger_density\").alias(\"mean_passenger_dens\"),\n",
    "    F.mean(\"crew\").alias(\"mean_crew\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a1036-b3ae-4f5e-a78a-1ba122f6611d",
   "metadata": {},
   "source": [
    "There are 20 different cruise lines in the data set.\n",
    "\n",
    "* Royal Carribbean and Carnival are the most prominent with cruise lines with 20+ ships each. Princess comes in 3rd with 17 ships with Holland American and Norwegian rounding out the top 5 cruise liners with the most ships. These 5 cruise lines account for 89 of the 158 ships in the data set (approx. 56%).\n",
    "\n",
    "* Amongst the top 5 cruise lines, Norwegian and Holland American generally have the oldest ships at an average of 17 years old. Princess generally has the newest ships at an average of 13 years old.\n",
    "\n",
    "* Royal Carribbean has the highest average passenger capacity at ~2,885 passengers. Seabourn generally has some of oldest ships while also having the lowest passenger capacity at about 208 passengers. This isn't surprising since Royal Carribbean also boasts the highest average tonnage at 107,000 tons. What is surprising is Carnival has a higher average passenger capacity than Princess and Cunard, despite having a lower average tonnage per ship.\n",
    "\n",
    "* Cruise ship lengths are roughly comparable across the top 5 cruise lines ranging from 7,800 ft to 9,600 ft. Royal Carribbean again takes the top spot with the longest ships on average.\n",
    "\n",
    "* Unsurprisingly, Royal Carribbean also has the highest average cabin count at ~1,300 cabins. This makes sense since Royal Carribbean has the highest average passenger capacity, so they would require more cabins to accommodate passengers. By similar logic, it is unsurprising that Seabourn (having the lowest average passenger capacity) would also have the lowest average cabin count at ~100.\n",
    "\n",
    "* Royal Carribbean ships boast the largest ships on average, but surprisingly are slightly behind Cunard and Carnival in average crew count. Cunard does have an average tonnage that rivals Royal Carribbean. What is surprising is that Carnival ships have noticeably less tonnage than both Royal and Cunard, while having a lower average passenger capacity than Royal Carribean. Yet Carnival ranks second in average crew count per ship. This might be due to Carnival having unique staffing mixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36acbe-3ed4-4c3b-bb05-c8742604431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the correlation matrix of the numeric columns\n",
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"Tonnage\",\n",
    "    \"passengers\",\n",
    "    \"length\",\n",
    "    \"cabins\",\n",
    "    \"passenger_density\",\n",
    "    \"crew\"\n",
    "]\n",
    "\n",
    "numeric_assembler = VectorAssembler(\n",
    "    inputCols = numeric_cols,\n",
    "    outputCol = \"features\"\n",
    ")\n",
    "\n",
    "# use the Correlation object pyspark to get the correlation matrix;\n",
    "# note that the corr() method requires us to assemble all the \n",
    "# numeric columns into a single vector\n",
    "cor_mat = Correlation.corr(numeric_assembler.transform(df).select(\"features\"), column = \"features\", method = \"pearson\")\n",
    "\n",
    "# the correlation matrix is stored as a single entry\n",
    "# in a 1x1 dataframe, which we need to extract\n",
    "cor_mat = cor_mat.collect()[0][\"pearson(features)\"]\n",
    "\n",
    "# coerce into a pandas dataframe for visualization\n",
    "cor_mat = cor_mat.toArray().tolist()\n",
    "\n",
    "cor_mat = pd.DataFrame(cor_mat, columns = numeric_cols, index = numeric_cols)\n",
    "\n",
    "sns.heatmap(cor_mat, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d6975-d1f1-4a57-bc0e-63c7b661b532",
   "metadata": {},
   "source": [
    "The correlation matrix gives us a preliminary idea about how the different variables are related to each other.\n",
    "\n",
    "* Unsurprisingly, `Tonnage`, `passengers`, `legnth`, and `cabins` are all highly correlated with each other. This makes sense larger ships are needed for more cabins to fit more passengers.\n",
    "  \n",
    "* `Age` is negatively correlated with `Tonnage`, `passengers`, `length`, and `cabins`. This makes sense new technology generally makes it easier to build larger cruise ships.\n",
    "\n",
    "* `crew` is positively correlated with `Tonnage`, `passengers`, `length` and `cabins`; this make sense since larger ships and more passengers will naturally require more crew members to manage and service. `crew` is negatively correlated with `Age`, which also makes sense since newer ships generally tend to be larger (as demonstrated by the negative correlation between `Age` and size).\n",
    "\n",
    "* `passenger_density` doesn't really exhibit strong correlations with any variable in particular. This likely because `passenger_density` is a normalized value.\n",
    "\n",
    "Generally speaking, size of the ship is most correlated with crew count. The 4 variables `Tonnage`, `passengers`, `length`, and `cabins` are highly collinear with each other, indicating that these variables are all measuring the same latent concept of \"size\". If we wish to have \"simple\" model, we probably wouldn't lose too much information by dropping 1 or 2 of these variables. \n",
    "\n",
    "Another thing to note is that Carnival had a higher average crew count than Royal Caribbean despite having noticeable smaller ships on average. This is likely due to intrinsic differences in how Carnival ships are staffed vs Royal Caribbean (and other cruise lines). In particular, we might want to add a dummy variable for each cruise line to control for the \"between cruise line\" staffing variations. However, this might not be feasible since some cruise lines only have 1 ship (i.e. Orient). In light of this, we will start by including a single dummy variable to indicate whether a ship belongs to Carnival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598b366-ed3f-4355-9489-0927358166dc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4d475-5ac9-478d-9a5c-6e799a5ded52",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888255d-131b-42be-abab-21f943854d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an indicator for Carnival ships\n",
    "df_model = df.withColumns(\n",
    "    {\n",
    "        \"is_carnival\" : F.when(df[\"Cruise_line\"] == \"Carnival\", 1).otherwise(0)\n",
    "    }\n",
    ")\n",
    "\n",
    "inputCols = [\n",
    "    \"Age\",\n",
    "    \"Tonnage\",\n",
    "    \"passengers\",\n",
    "    \"length\",\n",
    "    \"cabins\",\n",
    "    \"is_carnival\"\n",
    "]\n",
    "    \n",
    "\n",
    "# assemble features into vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = inputCols,\n",
    "    outputCol = \"features\"\n",
    ")\n",
    "\n",
    "df_model = assembler.transform(df_model)\n",
    "\n",
    "df_model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e331c60-793e-4c85-83ac-72347f26bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "df_train, df_test = df_model.randomSplit([0.7, 0.3], seed = SEED)\n",
    "\n",
    "print(f\"Training Data Size: {df_train.count()}\")\n",
    "print(f\"Testing Data Size: {df_test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421cade-a0ba-438f-b22f-bd13c6697494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit inital model\n",
    "lr_estimator = LinearRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"crew\",\n",
    "    predictionCol = \"prediction\"\n",
    ")\n",
    "\n",
    "lr_model = lr_estimator.fit(df_train)\n",
    "\n",
    "lr_summary = lr_model.summary\n",
    "\n",
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a08883-2b54-4149-ba04-a1097b3d52c4",
   "metadata": {},
   "source": [
    "Note that the `passenger` coefficient is estimated to be -0.15 which doesn't make real-world sense and is likely due to the heavy multicollinearity between `passenger` and the other predictors. For the purposes of prediction, this isn't an issue since we don't actually need to justify why the coefficient should be negative as long as the model to predicts accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247ca28-2b40-4625-9d2f-d5a4e8f9c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view errors on training set\n",
    "print(f\"R2: {lr_summary.r2}\")\n",
    "print(f\"Adjusted R2: {lr_summary.r2adj}\")\n",
    "print(f\"Train MSE: {lr_summary.meanSquaredError}\")\n",
    "print(f\"Train RMSE: {lr_summary.rootMeanSquaredError}\")\n",
    "print(f\"Train MAE: {lr_summary.meanAbsoluteError}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a5a95-2a84-4630-a2c9-f56e992fa55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view results on test set\n",
    "test_results = lr_model.evaluate(df_test)\n",
    "\n",
    "print(f\"Test MSE: {test_results.meanSquaredError}\")\n",
    "print(f\"Test RMSE: {test_results.rootMeanSquaredError}\")\n",
    "print(f\"Test MAE: {test_results.meanAbsoluteError}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adaf329-a2c6-4717-b5b2-c25ced6f2ae9",
   "metadata": {},
   "source": [
    "The model has an adjusted $R^2$ of about 0.95, so ~95% of the variance in `crew` (in the training data set) is explained by the model using just 6 variables (this is very good!). However, the mean squared error is more than 3x on the testing data set than the training data set, which indicates the model might be overfitting. However, it's also possible that the high test error is due to random chance; the test data only contains 45 data points after all. We could properly investigate this by doing cross validation (either k-fold or leave-one-out), which requires a bit of code to get up and running. An easier proxy is to bootstrap the test MSE by changing the random seed of `randomSplit()` $n$-many times to generate $n$ different versions of train-test splits. We can then fit the model on the training set and evaluate on the testing set $n$-many times; averaging out the train and test MSE's would give us a \"bootstrapped\" MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0f7b2-cb1c-4e08-ac5a-2eb674e28250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    df_train, df_test = df_model.randomSplit([0.7, 0.3], seed = i)\n",
    "    lr_estimator = LinearRegression(\n",
    "        featuresCol = \"features\",\n",
    "        labelCol = \"crew\",\n",
    "        predictionCol = \"prediction\"\n",
    "    )\n",
    "    \n",
    "    lr_model = lr_estimator.fit(df_train)\n",
    "    train_mse = lr_model.summary.meanSquaredError\n",
    "    test_mse = lr_model.evaluate(df_test).meanSquaredError\n",
    "\n",
    "    train_mse_list.append(train_mse)\n",
    "    test_mse_list.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cfdde-63ba-48b6-a487-e17f9f59497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Avg Train MSE: {sum(train_mse_list)/len(train_mse_list)}\")\n",
    "print(f\"Avg Test MSE: {sum(test_mse_list)/len(test_mse_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e86bc-938a-46be-9f32-43af4e6a326f",
   "metadata": {},
   "source": [
    "Using a bootstrap sample of size 50, the estimated Train and Test MSE values are pretty close, indicating that the model isn't likely to be overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa847b9-8511-489c-902e-1bd77ecd30ac",
   "metadata": {},
   "source": [
    "Despite the results of the bootstrap, let's see what would happen if we assumed the model was overfitting. In this case, there would be 2 options:\n",
    "\n",
    "1) Drop some variables to reduce the model complexity. For example, it's likely that `passenger` and `cabin` both measure the same thing and having both variables isn't likely to give us any new information that isn't just random noise. We can automate the variable selection process using a number of techniques, but the easiest one to use would be LASSO aka L1-penalty.\n",
    "\n",
    "2) Limit the range of possible models by restricting the size of the coefficients. For example, since `passenger` and `cabin` likely measure the same thing, it would make sense to keep their coefficients at roughly the same magnitude. The the most common way to restrict coefficient size is to use Ridge aka L2-penalty.\n",
    "\n",
    "LASSO, Ridge, and their hybrid child ElasticNet both come pre-buil with the `LinearRegression` estimator; we just need to pass in the following arguments:\n",
    "\n",
    "* `regParam` stipulates the size of the penalty term. Larger values will lead to stronger regularization and will more aggressively reduce overfitting (at the cost of increasing underfitting). The optimal `regParam` is usually found by hyperparameter tuning via cross-validation.\n",
    "\n",
    "* `elasticNetParam` gives the weighting of the L1 vs L2-penalty terms. A value of 0 will use all L2-penalty (resulting in Ridge), while a value of 1 will use all L1-penalty (resulting in LASSO). An **ElasticNet** model is any model where the value is strictly between 0 and 1, i.e. the model uses a weighted average of L1 and L2 penalty terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ade87-5b2d-48f5-9a31-5ffca8fb135c",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41139e00-f937-40a8-bb28-5fdb93e99cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit inital model\n",
    "lasso_estimator = LinearRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"crew\",\n",
    "    predictionCol = \"prediction\",\n",
    "    regParam = 0.1,  # size of the penalty term; usually chosen via cross-validation\n",
    "    elasticNetParam = 1, # L1 vs L2 weighting; 0 = ridge vs 1 = LASSO\n",
    ")\n",
    "\n",
    "lasso_model = lasso_estimator.fit(df_train)\n",
    "\n",
    "lasso_summary = lasso_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb12e3b-714d-4520-94a1-689a72833fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4c816-a1f1-41fb-928a-62d05f38b34d",
   "metadata": {},
   "source": [
    "This LASSO model with a penalty weight of 0.1 set the `passengers` coefficient to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d77eab-19dd-4704-9ac1-918c30833b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view errors on training set\n",
    "print(f\"R2: {lasso_summary.r2}\")\n",
    "print(f\"Adjusted R2: {lasso_summary.r2adj}\")\n",
    "print(f\"Train MSE: {lasso_summary.meanSquaredError}\")\n",
    "print(f\"Train RMSE: {lasso_summary.rootMeanSquaredError}\")\n",
    "print(f\"Train MAE: {lasso_summary.meanAbsoluteError}\")\n",
    "\n",
    "print(\"\\n-------------------\\n\")\n",
    "# view results on test set\n",
    "test_results = lasso_model.evaluate(df_test)\n",
    "\n",
    "print(f\"Test MSE: {test_results.meanSquaredError}\")\n",
    "print(f\"Test RMSE: {test_results.rootMeanSquaredError}\")\n",
    "print(f\"Test MAE: {test_results.meanAbsoluteError}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20387e-1210-40a0-aec0-c282e3d24f79",
   "metadata": {},
   "source": [
    "Adding regularization actually causes testing error to go up, which might indicate that the model is actually underfit (and that the original test MSE of 1.8 was a freak outlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47813ce2-87db-4c03-bd76-4719ba9e1b50",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e68e1-5c4a-4a99-bd31-10a51466d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit inital model\n",
    "ridge_estimator = LinearRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"crew\",\n",
    "    predictionCol = \"prediction\",\n",
    "    regParam = 0.1,  # size of the penalty term; usually chosen via cross-validation\n",
    "    elasticNetParam = 0, # L1 vs L2 weighting; 0 = ridge vs 1 = LASSO\n",
    ")\n",
    "\n",
    "ridge_model = ridge_estimator.fit(df_train)\n",
    "\n",
    "ridge_summary = ridge_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d32ea-c137-42ac-b0e7-e2e4d3f80521",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c297c0-e99c-4b37-992c-644c115e7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view errors on training set\n",
    "print(f\"R2: {ridge_summary.r2}\")\n",
    "print(f\"Adjusted R2: {ridge_summary.r2adj}\")\n",
    "print(f\"Train MSE: {ridge_summary.meanSquaredError}\")\n",
    "print(f\"Train RMSE: {ridge_summary.rootMeanSquaredError}\")\n",
    "print(f\"Train MAE: {ridge_summary.meanAbsoluteError}\")\n",
    "\n",
    "print(\"\\n-------------------\\n\")\n",
    "# view results on test set\n",
    "test_results = ridge_model.evaluate(df_test)\n",
    "\n",
    "print(f\"Test MSE: {test_results.meanSquaredError}\")\n",
    "print(f\"Test RMSE: {test_results.rootMeanSquaredError}\")\n",
    "print(f\"Test MAE: {test_results.meanAbsoluteError}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacb39d-e59f-4eec-9702-e181d42c031e",
   "metadata": {},
   "source": [
    "Again, adding regularization causes test MSE to go up, so it's unlikely that the model is that severely overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe51812-5674-442b-bc80-ffe40ee665d2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
