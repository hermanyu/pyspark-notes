{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd6c94d-1d1c-4bce-9a6c-592ed7253795",
   "metadata": {},
   "source": [
    "# 03 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a15868-5e1e-4177-8d93-c435293475a8",
   "metadata": {},
   "source": [
    "## 3.1 The `MLlib` Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef99be-1b91-42d5-a0c3-fc0d89512662",
   "metadata": {},
   "source": [
    "PySpark comes equipped with the `MLlib`, Spark's own machine learning library (the documentation can be found here <a href=\"https://spark.apache.org/docs/latest/ml-guide.html\">MLlib: Main Guide</a>). As a quick overview of how the library is designed, here are the key principals:\n",
    "\n",
    "1) A `Transformer` is an abstraction for something that transforms a dataframe. The `Transformer` concept is an umbrella term for 2 kinds of transformers: feature transformers and learned models. A feature transformer will generate new features based on existing features, while a learned model will generate a prediction column based on some feature columns.\n",
    "\n",
    "2) An `Estimator` is an abstraction for the concept of a learning algorithm (or any algorithm that fits/trains on the data). An `Estimator` implements an abstract method called `fit()` which takes in a dataframe and outputs a `Transformer` (the fitted model). In Java vernacular, the `LinearRegression` class implements the `Estimator` class and produces a `LinearRegressionModel` object.\n",
    "\n",
    "3) A `Pipeline` is a sequential collection of `Transformer` objects and `Estimators` objects. The idea is that the dataframe is undergoes processing by various `Transformer` objects, then is fed into an `Estimator` object to produce a fitted model; the output should be a fitted model (hence a `Transformer` object). A `Pipeline` packages all the data processing and model fitting into a single object. This is useful for data that requires very involved processing steps like text-data and images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826fca79-3b8d-4d85-9f08-e93b41dda4dc",
   "metadata": {},
   "source": [
    "## 3.1 The Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7193c4ab-6cc4-4215-a7ca-0e2912f20c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate new spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "DATA_PATH = \"../course_materials/Spark_for_Machine_Learning/Linear_Regression/\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Linear Regression\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb95593-0d46-4c98-a209-2797f50f2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df_sample = spark.read.format(\"libsvm\").load(DATA_PATH + \"sample_linear_regression_data.txt\")\n",
    "\n",
    "df_sample.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c620a79-c2f8-45a9-8875-3fe88288d96e",
   "metadata": {},
   "source": [
    "Notice in particular: the `features` column seems to contain an entire row vector in each entry. This is indeed the case and we can verify with `printSchema()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ed0c73-0475-4eba-b21c-1ad29bff8341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fe066-f5ea-4a85-a62a-cf795747e2a1",
   "metadata": {},
   "source": [
    "The reason for this is because `Estimator` objects expect all the features to be packaged into a single row vector and will look for a single column containing that vector. Note the `10` in the front of each vector indicates the size of the vector; in this case each row consists of a 10-dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a4080-7d0d-4317-a9fc-e89e2f80d957",
   "metadata": {},
   "source": [
    "## 3.2 The `LinearRegression` Estimator And `LinearRegressionModel` Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8522faf-9b11-48d6-afdb-e2250878e009",
   "metadata": {},
   "source": [
    "The `LinearRegression` estimator is used to build linear regression models using gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766dc2df-9517-4699-be16-f8f1413d732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a98d92-c38e-4f04-b9b1-bdb877cd0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a LinearRegression estimator\n",
    "lr_estimator = LinearRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"label\",\n",
    "    predictionCol = \"prediction\"\n",
    ")\n",
    "\n",
    "# use the estimator to fit a model\n",
    "lr_model = lr_estimator.fit(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd168122-b5a9-49c1-a89e-0f8163f73146",
   "metadata": {},
   "source": [
    "The `LinearRegression` estimator is an object with a `fit()` method. The `fit()` method returns a `LinearRegressionModel` object and this object has `coefficient` and `intercept` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201d9984-65bb-44bd-9275-556996aef821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0073350710225801715,0.8313757584337543,-0.8095307954684084,2.441191686884721,0.5191713795290003,1.1534591903547016,-0.2989124112808717,-0.5128514186201779,-0.619712827067017,0.6956151804322931]\n",
      "0.14228558260358093\n"
     ]
    }
   ],
   "source": [
    "# view fitted coefficients and intercepts\n",
    "print(lr_model.coefficients)\n",
    "\n",
    "print(lr_model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027fef1-028f-46b6-8eba-734c68cc06e8",
   "metadata": {},
   "source": [
    "We can look at various goodness-of-fit metrics by looking at a `LinearRegressionSummary` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f04754-8280-4971-af0a-334f9e21ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027839179518600154\n",
      "103.28843028724194\n",
      "10.16309157133015\n",
      "8.145215527783876\n",
      "[0.8068799897284031, 0.817504726374364, 0.8095690515350549, 0.8435177715251213, 0.8066923009911938, 0.8238680228428261, 0.8041910472918519, 0.8095101717564966, 0.8428997032677101, 0.788760166505627, 0.46405794834415603]\n",
      "[0.9927505031240562, 0.30967074330990396, 0.3178269194409711, 0.003972477331573909, 0.5201486327242175, 0.16213017210149872, 0.7102819001865635, 0.5266812209137877, 0.46256007153356316, 0.37825808848978526, 0.7592692146070568]\n",
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|  1.5211201432720063|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...| -0.6658770747591632|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.1568703823211514|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.6374146679690593|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|   2.372566473232916|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -1.9410651727650883|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  2.2621027950886363|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|-0.00134792656609...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -3.0051104606414007|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  3.5437265095387804|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...| -0.4889664122481736|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.5073098457843013|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|   3.002580330272542|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.6644891587448811|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|   1.837123449000886|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|  -2.499423280435292|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|  -2.640384817630781|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -1.853286585458312|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|   2.236000785795242|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  0.9090111490574454|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract a LinearRegressionSummary object\n",
    "model_summary = lr_model.summary\n",
    "\n",
    "# look at model R^2\n",
    "print(model_summary.r2)\n",
    "\n",
    "# look at model MSE\n",
    "print(model_summary.meanSquaredError)\n",
    "\n",
    "# look at model Root MSE\n",
    "print(model_summary.rootMeanSquaredError)\n",
    "\n",
    "# look at model MAE\n",
    "print(model_summary.meanAbsoluteError)\n",
    "\n",
    "# look at the standard errors of the coefficient estimates\n",
    "# note that the last element corresponds to the intercept\n",
    "print(model_summary.coefficientStandardErrors)\n",
    "\n",
    "# look at the p-values of the coefficient estimates\n",
    "print(model_summary.pValues)\n",
    "\n",
    "# view the predicted outputs of each row in the training data\n",
    "model_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b793cf8-0447-4b14-ade3-7d5735ad0df0",
   "metadata": {},
   "source": [
    "Recall that fitted models are implementations of an abstract `Transformer` class because they \"transform\" input features into predictions. We can generate predictions using the `Transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee70242-4bfa-4bf3-9026-cabb38f42683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|  1.5211201432720063|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...| -0.6658770747591632|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.1568703823211514|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.6374146679690593|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|   2.372566473232916|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -1.9410651727650883|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  2.2621027950886363|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|-0.00134792656609...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -3.0051104606414007|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  3.5437265095387804|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...| -0.4889664122481736|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.5073098457843013|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|   3.002580330272542|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.6644891587448811|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|   1.837123449000886|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|  -2.499423280435292|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|  -2.640384817630781|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -1.853286585458312|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|   2.236000785795242|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  0.9090111490574454|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate predictions from some input data\n",
    "predictions = lr_model.transform(df_sample)\n",
    "\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c02f2-80fd-4237-aab4-e4e454237ca8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2fe374-239f-4d0f-a3cf-4d339474dfc1",
   "metadata": {},
   "source": [
    "## 3.3 Vectors and Vector Assemblers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5947ede-4a29-438f-b95d-f2f8b8cfaabf",
   "metadata": {},
   "source": [
    "As noted in the previous section, `Estimator` objects only take in a single column as the feature. This is because MLlib requires us to assemble all of our input values into a single array called a `Vector`. Each row of the training data has a single feature `Vector` as input. To assemble multiple columns of a dataframe into a single `Vector`, we use a feature transformer called a `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e02f22a-4bc0-4458-8bd7-a2c672b8d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# load \"unprepared\" data\n",
    "df_ecomm = spark.read.csv(DATA_PATH + \"Ecommerce_Customers.csv\", inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ae3080-5f1d-4742-9425-a6047dd1b377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Rows: 500\n",
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|               Email|             Address|          Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|\n",
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|          Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|       DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|          Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|\n",
      "|riverarebecca@gma...|1414 David Throug...|     SaddleBrown| 34.30555662975554|13.717513665142507| 36.72128267790313|   3.120178782748092|  581.8523440352177|\n",
      "|mstephens@davidso...|14023 Rodriguez P...|MediumAquaMarine| 33.33067252364639|12.795188551078114| 37.53665330059473|   4.446308318351434|  599.4060920457634|\n",
      "|alvareznancy@luca...|645 Martha Park A...|     FloralWhite|33.871037879341976|12.026925339755056| 34.47687762925054|   5.493507201364199|   637.102447915074|\n",
      "|katherine20@yahoo...|68388 Reyes Light...|   DarkSlateBlue| 32.02159550138701|11.366348309710526| 36.68377615286961|   4.685017246570912|  521.5721747578274|\n",
      "|  awatkins@yahoo.com|Unit 6538 Box 898...|            Aqua|32.739142938380326| 12.35195897300293| 37.37335885854755|  4.4342734348999375|  549.9041461052942|\n",
      "|vchurch@walter-ma...|860 Lee KeyWest D...|          Salmon| 33.98777289568564|13.386235275676436|37.534497341555735|  3.2734335777477144|  570.2004089636196|\n",
      "|    bonnie69@lin.biz|PSC 2734, Box 525...|           Brown|31.936548618448917|11.814128294972196| 37.14516822352819|   3.202806071553459|  427.1993848953282|\n",
      "|andrew06@peterson...|26104 Alexander G...|          Tomato|33.992572774953736|13.338975447662113| 37.22580613162114|   2.482607770510596|  492.6060127179966|\n",
      "|ryanwerner@freema...|Unit 2413 Box 034...|          Tomato| 33.87936082480498|11.584782999535266| 37.08792607098381|    3.71320920294043|  522.3374046069357|\n",
      "|   knelson@gmail.com|6705 Miller Orcha...|       RoyalBlue|29.532428967057943|10.961298400154098| 37.42021557502538|   4.046423164299585|  408.6403510726275|\n",
      "|wrightpeter@yahoo...|05302 Dunlap Ferr...|          Bisque| 33.19033404372265|12.959226091609382|36.144666700041924|   3.918541839158999|  573.4158673313865|\n",
      "|taylormason@gmail...|7773 Powell Sprin...|        DarkBlue|32.387975853153876|13.148725692056516| 36.61995708279922|   2.494543646659249|  470.4527333009554|\n",
      "| jstark@anderson.com|49558 Ramirez Roa...|            Peru|30.737720372628182|12.636606052000127|36.213763093698624|  3.3578468423262944|  461.7807421962299|\n",
      "| wjennings@gmail.com|6362 Wilson Mount...|      PowderBlue| 32.12538689728784|11.733861690857394|  34.8940927514398|  3.1361327164897803| 457.84769594494855|\n",
      "|rebecca45@hale-ba...|8982 Burton RowWi...|       OliveDrab|32.338899323067196|12.013194694014402| 38.38513659413844|   2.420806160901484| 407.70454754954415|\n",
      "|alejandro75@hotma...|64475 Andre Club ...|            Cyan|32.187812045932155|  14.7153875441565| 38.24411459434352|   1.516575580831944|  452.3156754800354|\n",
      "|samuel46@love-wes...|544 Alexander Hei...|   LightSeaGreen| 32.61785606282345|13.989592555825254|37.190503800397956|   4.064548550437977|   605.061038804892|\n",
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Num. Rows: \" + str(df_ecomm.count()))\n",
    "df_ecomm.printSchema()\n",
    "df_ecomm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6d67b-fb22-4031-a066-8c68b74b5a7a",
   "metadata": {},
   "source": [
    "The dataframe contains ecommerce data. Let us build a linear regression model that predicts `Yearly Amount Spent` based on the `Avg Session Length`, `Time on App`, and `Length of Membership`. Notice that these predictor variables *are not* assembled into a single feature vector yet. To do this, use the `VectorAssembler` which is a **feature transformer** because it transforms our features into a new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687993ad-889e-45e4-b96c-70ad38425d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|               Email|             Address|          Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|            features|\n",
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|          Violet| 34.49726772511229| 12.65565114916675| 39.57766801952616|  4.0826206329529615|  587.9510539684005|[34.4972677251122...|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|       DarkGreen| 31.92627202636016|11.109460728682564|37.268958868297744|    2.66403418213262|  392.2049334443264|[31.9262720263601...|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|          Bisque|33.000914755642675|11.330278057777512|37.110597442120856|   4.104543202376424| 487.54750486747207|[33.0009147556426...|\n",
      "|riverarebecca@gma...|1414 David Throug...|     SaddleBrown| 34.30555662975554|13.717513665142507| 36.72128267790313|   3.120178782748092|  581.8523440352177|[34.3055566297555...|\n",
      "|mstephens@davidso...|14023 Rodriguez P...|MediumAquaMarine| 33.33067252364639|12.795188551078114| 37.53665330059473|   4.446308318351434|  599.4060920457634|[33.3306725236463...|\n",
      "+--------------------+--------------------+----------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputCols = [\n",
    "    \"Avg Session Length\",\n",
    "    \"Time on App\",\n",
    "    \"Time on Website\",\n",
    "    \"Length of Membership\"\n",
    "]\n",
    "\n",
    "# Instantiate a VectorAssembler object\n",
    "# by specifying the input cols\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = inputCols,\n",
    "    outputCol = \"features\" # name of the column to assemble to\n",
    ")\n",
    "\n",
    "# assemble our feature cols into a single vector of features\n",
    "# by calling the transform(); this takes in our original dataframe\n",
    "# and returns a new transformed dataframe\n",
    "df_ecomm_assembled = assembler.transform(df_ecomm)\n",
    "\n",
    "# view the new dataframe\n",
    "df_ecomm_assembled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ebd80-b9a1-4650-bca4-f252cb694965",
   "metadata": {},
   "source": [
    "Notice that the `VectorAssembler` transforms our original dataframe by creating a new column named `features` which contains a 4-dimensional vector of input values. We are now ready to fit a new linear regression model to this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c22f21d-3f7e-4d90-a7fe-1c213d906a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new LinearRegressionEstimator\n",
    "lr_estimator = LinearRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"Yearly Amount Spent\",\n",
    "    predictionCol = \"prediction\"\n",
    ")\n",
    "\n",
    "# fit a linear regression model to the data\n",
    "lr_model = lr_estimator.fit(df_ecomm_assembled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbba58f-08af-4c3b-a4eb-cca5547b7538",
   "metadata": {},
   "source": [
    "Let's examine the fittd parameters, $R^2$, and standard errors value of the fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0387390e-27e9-4955-a2f1-7a9e467a55f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R2: 0.9843155370226727\n",
      "Avg Session Length: 25.73  ,  SE: 0.45  ,  p-value: 0.0\n",
      "Time on App: 38.71  ,  SE: 0.45  ,  p-value: 0.0\n",
      "Time on Website: 0.44  ,  SE: 0.44  ,  p-value: 0.33\n",
      "Length of Membership: 61.58  ,  SE: 0.45  ,  p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "lr_summary = lr_model.summary\n",
    "\n",
    "print(f\"Model R2: {lr_summary.r2}\")\n",
    "\n",
    "results = zip(\n",
    "    inputCols,\n",
    "    lr_model.coefficients,\n",
    "    lr_summary.coefficientStandardErrors[0:4],\n",
    "    lr_summary.pValues[0:4]\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result[0]}: {round(result[1],2)}  ,  SE: {round(result[2],2)}  ,  p-value: {round(result[3], 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0defb49-5674-45a2-91da-5a6ef32b17ac",
   "metadata": {},
   "source": [
    "This model explains 98.4% of the variance in `Yearly Amount Spent` (which is really good!). `Avg Session Length`, `Time on App`, and `Length of Membership` are all positively correlated with `Yearly Amount Spent` once we control for each of them in the model; this isn't too surprising. What is surprising is that `Time on Website` does not seem to have a strong relationship with `Yearly Amount Spent` in the presence of the other variables. This is could possibly be explained by multicollinearity between `Time on Website` and the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c15ea3-2b95-4f6f-8665-8db07f147742",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec025e-ecfb-4663-a141-3946b7009544",
   "metadata": {},
   "source": [
    "## 3.4 Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69113f4-1650-4c32-a8a4-9a5e90bb32f1",
   "metadata": {},
   "source": [
    "Generally speaking, linear models come in 2 flavors:\n",
    "\n",
    "1) Models for **inference** are models meant to study real world relationships between observed variables. Models in classical statistics / econometrics typically fall into this category. Inferential models mainly care about interpretability and the standard errors of the estimated coefficients. For this reason, inferential models are generally fit on *all* of the available data. Standard errors are computed by making strong mathematical assumptions about the underlying data generation process, so special attention must be paid to checking whether the observed data seems to align with the assumptions being made.\n",
    "\n",
    "2) Models for **prediction** are models meant to generating a predicted value. Models in machine learning typically fall into this category. Predictive models mainly care about **generalization accuracy**, i.e. how accurately the model predicts on *new* data. For this reason, the data set is usually split into a *training* set and a *testing* set. The model is trained on the training set, then asked to make predictions on the testing set. The accuracy on the testing set serves as an estimate for the models generalization accuracy and this is usually measured by the **mean squared error** of the testing data set.\n",
    "\n",
    "The 2 flavors of linear models do not inherently conflict with each other, but they do generally require the model builder to evaluate the models using different metrics. This in important to keep in mind because there is no \"one-size-fits-all\" approach to model building. The things we do when building a model will always be dictated by what we want the use the model for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31e9b8-3d1d-4a05-9709-aa73948dc385",
   "metadata": {},
   "source": [
    "Suppose we wanted to build a predictive model. Then what we care about is the **generalization error**, i.e. how accurate the model is on never-before-seen data. Realistically, it's not possible to know how the model would perform on data we don't have. So the next best alternative is *estimate* the generalization error by holding out a subset of the data to test the model on. This procedure is called a **train-test split** and we can do this split on a Spark dataframe by using the `randomSplit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f036d1b-5591-4e60-9406-0894ce4acba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|               Email|             Address|        Avatar|Avg Session Length|       Time on App|   Time on Website|Length of Membership|Yearly Amount Spent|            features|\n",
      "+--------------------+--------------------+--------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "|   aaron04@yahoo.com|16338 Scott Corne...|      SeaGreen| 33.70511279750195|10.163179060052556|37.763041081545246|   4.778973636034999|  521.2407802357949|[33.7051127975019...|\n",
      "|    aaron11@luna.com|672 Jesus Roads A...|  LightSkyBlue| 32.44952156114242| 13.45772494051235| 37.23880567308968|   2.941410754428091|  503.9783790525795|[32.4495215611424...|\n",
      "|   aaron22@gmail.com|38678 Sean Drive ...|      DarkGray|33.452295280190306|12.005916370756164| 36.53409567089256|   4.712233578509767|  576.4776071703129|[33.4522952801903...|\n",
      "|   aaron89@gmail.com|0128 Sampson Loop...|   SaddleBrown|31.447446494127817|10.101632204781014|38.043452650841274|   4.238296188412728|   418.602742095224|[31.4474464941278...|\n",
      "|acampbell@sanchez...|5791 Jessica Cove...|         Wheat|32.425697279750864|11.448901535513794|37.580190429177314|  2.5869679851624765| 420.73767324463716|[32.4256972797508...|\n",
      "|acontreras@hotmai...|88995 Edwards Row...|        Sienna|  33.5477479443078|10.735362917985057| 37.45837473122322|  3.8634254422050343|  476.1914133494556|[33.5477479443078...|\n",
      "|adamperkins@terre...|2595 James Creek ...| PaleVioletRed| 32.60273898042012|11.764447589452988|   37.922703809566|  3.5258064121952244| 482.14499687576796|[32.6027389804201...|\n",
      "|       afry@ford.biz|399 Jeremy Skyway...| PaleTurquoise|32.291756100263015|12.190474287309025| 36.15246208860067|   3.781823039343296| 494.55186108657256|[32.2917561002630...|\n",
      "|   agolden@yahoo.com|PSC 2490, Box 212...|         Black|33.503087256719716| 12.87798369625634| 37.44102133556604|   1.559151939957077| 419.93877483917913|[33.5030872567197...|\n",
      "|alejandro75@hotma...|64475 Andre Club ...|          Cyan|32.187812045932155|  14.7153875441565| 38.24411459434352|   1.516575580831944|  452.3156754800354|[32.1878120459321...|\n",
      "|alexandermichael@...|2086 Lisa ViewOrt...|    WhiteSmoke| 32.69323953887129|12.600750401563928| 37.37011822360151|   3.467014066009709|  501.9282648732441|[32.6932395388712...|\n",
      "|alexandra26@summe...|Unit 7032 Box 701...|          Navy| 32.83694076702139| 10.25654903128796|36.143908456341634|  0.7895199078816915| 256.67058229005585|[32.8369407670213...|\n",
      "|alvaradoadam@jone...|35970 Holly KeyPo...|    Aquamarine|31.954903856634846|10.963131776054833|37.327282689879496|  3.5786339003939878|   439.997879939927|[31.9549038566348...|\n",
      "|amandadean@gmail.com|66880 Mckinney Hi...|       DimGray|32.063774620313694|10.719149740628396| 37.71250863884946|   3.004742535925674|  378.3309069068038|[32.0637746203136...|\n",
      "|amberchase@fowler...|1867 Gregory Isle...|   GreenYellow| 33.92529660119954|11.588655423353044| 35.25224202243303|  3.3920504890738385| 483.67330801904563|[33.9252966011995...|\n",
      "|andreperez@hotmai...|17463 George Port...|DarkOliveGreen| 32.95976431107423|11.546275759510358|36.947953692845566|  3.2750706813095327| 448.34042501104767|[32.9597643110742...|\n",
      "|andrew06@peterson...|26104 Alexander G...|        Tomato|33.992572774953736|13.338975447662113| 37.22580613162114|   2.482607770510596|  492.6060127179966|[33.9925727749537...|\n",
      "|angelaphillips@gm...|102 Karen CourtNe...|     MintCream|32.657268594778124|11.957923064554107| 36.63465232853774|   4.106055151602658|  516.8315566841785|[32.6572685947781...|\n",
      "|anneingram@miller...|4301 Park Lake Ap...|      HoneyDew| 32.13386240984833|11.612650769570312| 39.24880390433504|  3.3492453825271813|  443.4418600624623|[32.1338624098483...|\n",
      "|antonioharris@hot...|4307 Nicholas Dri...|    MediumBlue| 33.70088553901973|13.471577671948914|37.071643198252396|  2.3790764968915394| 492.55683370047706|[33.7008855390197...|\n",
      "+--------------------+--------------------+--------------+------------------+------------------+------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train-test split w/ 70% of the data in training set\n",
    "# and the remaining 30% of the data in the testing set;\n",
    "# note that randomSplit() returns a 2-tuple so we can\n",
    "# \"unpack\" the tupleby assigning both\n",
    "# train and test dataframes at once\n",
    "df_train, df_test = df_ecomm_assembled.randomSplit([0.7, 0.3])\n",
    "\n",
    "df_train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ff997-b7db-40d5-8051-0b298fddb646",
   "metadata": {},
   "source": [
    "Note that we performed the train-test split on the dataframe where we had `feature` column already assembled in vector form; this is generally the recommended workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0af9a54-c9de-4609-831e-481eeb08aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on training data\n",
    "lr_model = lr_estimator.fit(df_train)\n",
    "\n",
    "# evaluate the model on test data\n",
    "test_results = lr_model.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb58989-a902-4c95-b7d0-78d8eed26231",
   "metadata": {},
   "source": [
    "We can now view how the model is expected to perform on never-before-seen data by viewing the prediction errors on the testing data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c160d07-a780-4de0-8801-7bed4319c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 130.44316439712264\n",
      "Test RMSE: 11.421171761125153\n",
      "Test MAE: 8.933644031864349\n",
      "+------------------------+\n",
      "|avg(Yearly Amount Spent)|\n",
      "+------------------------+\n",
      "|      500.40302478454294|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test MSE: {test_results.meanSquaredError}\")\n",
    "print(f\"Test RMSE: {test_results.rootMeanSquaredError}\")\n",
    "print(f\"Test MAE: {test_results.meanAbsoluteError}\")\n",
    "\n",
    "df_test.agg( {\"Yearly Amount Spent\" : \"mean\"} ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccc5a1-57ba-4802-b7da-943d60cea290",
   "metadata": {},
   "source": [
    "The Mean Absolute Error is ~8.5 so the model is +/- 8.5 on average from the correct value in the testing data. This seems pretty good considering the average `Yearly Amount Spent` in the test data is ~495 (so the model is +/- 1.7% on average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9211f-c8b4-46c9-962b-c05696e57721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
